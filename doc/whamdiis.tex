\documentclass[aip,jcp,preprint,superscriptaddress]{revtex4-1}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{color}
\begin{document}




\newcommand{\vct}[1]{\mathbf{#1}}
\newcommand{\vx}{\vct{x}}
\newcommand{\Z}{\mathcal{Z}}
\newcommand{\E}{\mathcal{E}}




\title{Accelerating the weighted histogram analysis method
by direct inversion in the iterative subspace}

\begin{abstract}
The convergence of the weighted histogram analysis method for free energy calculation
was improved by using the method of direct inversion in the iterative subspace.
\end{abstract}

\maketitle



\section{Introduction}





The multiple histogram method\cite{
ferrenberg1988, *ferrenberg1989}
or its generalization,
the weighted histogram analysis method (WHAM)\cite{
kumar1992, souaille2001, kastner2005,
chodera2007, bereau2009,
kim2011},
is a popular method
for free energy calculation.
%
The method iteratively solves a pair of coupled equations of
the free energy and the density of states
involving the energy histograms, hence the name.
%
It can be also reformulated
to avoid the histogram dependence,
resulting the
multistate Bennett acceptance ratio (MBAR) method\cite{
shirts2008},
extending the Bennett acceptance ratio (BAR) method\cite{
bennett1976}.



The straightforward implementation of WHAM or MBAR,
however, can suffer from
a slow convergence in later stages.
%
Several remedies were proposed\cite{
 shirts2008, bereau2009, kim2011}.
%
For example, one may use the Newton-Raphson method
to directly compute the Hessian matrix\cite{
shirts2008},
although it can be occasionally unstable.
%
An ingenious non-iterative alternative
is to directly estimate the derivative of density of states,
leading to the statistical-temperature WHAM\cite{
kim2011}.
%
This variant, however, gives
a slightly different estimate of free energy
from the original WHAM,
and the extension to multidimensional,
e.g., isothermal-isobaric, ensembles
is not obvious.



Here, we consider improving WHAM using
the method of direct inversion in the iterative subspace (DIIS)\cite{
pulay1980, *pulay1982, *hamilton1986}.
%
Particularly, we consider a modification
popular in the liquid state theory\cite{
kovalenko1999, howard2011}.





\section{Method}





\subsection{WHAM}



WHAM is a method of
estimating the free energy differences
among a few thermodynamic states
with different parameters,
such as temperatures, pressures, etc.
%
For definiteness,
consider the special case of $K$ temperatures,
labeled by the inverse temperature,
$\beta = 1/(k_B T)$,
as
$\beta_1, \ldots, \beta_K$.
%
Suppose we have performed the respective
canonical-ensemble simulations
at the $K$ temperatures,
we wish to estimate the free energies
at the temperatures.



In WHAM,
we first estimate the density of states $g(E)$ from
%
\begin{equation}
g(E)
=
\frac{
  \sum_{j = 1}^K n_j(E)
}
{
  \sum_{k = 1}^K N_k \, \exp(-\beta_k E) / Z_k
},
\label{eq:gE_WHAM}
\end{equation}
%
where,
$n_j(E)$
is the unnormalized energy distribution
observed from simulation $j$.
%
This quantity is usually estimated
from the energy histogram as
the number of independent trajectory frames
whose energies fall in the interval
$(E - \Delta E/2, E + \Delta E/2)$
divided by $\Delta E$
(we shall omit ``independent'' below for simplicity).
%
$N_k$
is the total number of frames
from simulation $k$.
%
$Z_k$
is the partition function,
defined as
%
\begin{equation}
Z_k
=
\int g(E) \, \exp(-\beta_k E) \, dE.
\label{eq:Z}
\end{equation}




Eliminating $g(E)$
from Eqs. \eqref{eq:gE_WHAM} and \eqref{eq:Z},
we find the unitless free energy
$f_i \equiv -\log Z_i$
as
\begin{align}
f_i
&=
-\log
  \int
    \frac{
      \sum_{j = 1}^K n_j(E) \, \exp(-\beta_j E)
    }
    {
      \sum_{k = 1}^K N_k \, \exp(-\beta_k E + f_k)
    }
    dE
\label{eq:f_WHAM}
\\
&\equiv
-\log \Z_i(\{ f_k \}),
\notag
\end{align}
%
where,
$\Z_i$
denotes the integral on the right hand side.



In the above,
$n_j(E)$ is estimated from the energy histogram.
%
This dependency can be avoided
by noticing from definition
%
\begin{equation}
n_j(E)
=
\sum_{\vx}^{(j)} \delta(\E(\vx) - E),
\label{eq:n_delta}
\end{equation}
%
where,
$\E$
is the energy function,
and
$\sum_{\vx}^{(j)}$
denotes the sum over trajectory frames
of simulation $j$.
%
%
%
Using Eq. \eqref{eq:n_delta} in Eq. \eqref{eq:f_WHAM} yields
the MBAR\cite{shirts2008} result:
%
\begin{equation}
f_i
=
-\log
\sum_{j = 1}^K
\sum_{\vx}^{(j)}
\frac{
  \exp[-\beta_j \, \E(\vx)]
}
{
  \sum_{k = 1}^K N_k \exp[-\beta_k \, \E(\vx) + f_k]
}.
\label{eq:f_MBAR}
\end{equation}
%
%where,
%the denominator has been moved into the sum
%as it now depends on the configuration, $\vx$.



Several comments are in order.
%
First,
for simulations on multiple isothermal-isobaric ensembles
at different temperature and pressure,
%
we replace $E$ by $(E, V)$
and the Boltzmann weight
$\exp(-\beta_k \, E)$
by
$\exp(-\beta_k \, E - \beta_k \, p_k \, V)$,
with
$V$ and $p_k$
being the volume and pressure,
respectively.
%
Similarly,
non-Boltzmann weight\cite{
mezei1987, *berg1992, *lee1993, *tsallis1988}
can be used to replace the Boltzmann one
for simulations in non-canonical ensembles.
%
Finally,
once $g(E)$ is determined,
the free energy at an unsimulated temperature, $\beta$,
can be found from Eq. \eqref{eq:Z}
by substituting $\beta$ for $\beta_k$.


To determine $f_i$ numerically,
Eq. \eqref{eq:f_WHAM}
is usually treated as an iterative equation
%
\begin{equation}
f_i^\mathrm{(new)}
=
-\log \Z_i\left(
  \{ f_k^\mathrm{(old)} \}
\right).
\end{equation}
%
This is referred to as
the direct implementation below.
%
It can suffer from a slow convergence,
resulting in thousands of iterations\cite{
bereau2009, kim2011}.
%
Below we give a method to accelerate the process.





\subsection{DIIS}



DIIS is a method of solving a set of
(nearly) linear equations\cite{
pulay1980, *pulay1982, *hamilton1986,
kovalenko1999, howard2011}.
%
Here, it is used
to solve Eq. \eqref{eq:f_WHAM}.
%
A schematic illustration
is shown in Fig. \ref{fig:scheme}.
%
We first represent an approximate solution
by a trial vector,
$\vct f = (f_1, \dots, f_K)$,
which is, in our case, the vector of
the unitless free energies.
%
The equations can be written as
%
\begin{equation}
  R_i(\vct f) = 0  \quad i = 1, \ldots, K,
  \label{eq:R_f}
\end{equation}
%
whose left hand side forms a residual vector
$\vct R = (R_1, \dots, R_K)$.
%
Normally, the signs of $R_i$ are arranged such that
$\vct R(\vct f)$
gives a direction of reducing the error of $\vct f$.
%
That is,
for $\vct f' = \vct f + \alpha \, \vct R(\vct f)$
with a sufficiently small $\alpha$,
we expect
%
$\| \vct R(\vct f') \| < \| \vct R(\vct f) \|$.



Suppose now we have a basis consisting of $M$ trial vectors
$\vct f_1$, \dots $\vct f_M$
(where $M$ can be much less than $K$),
%
and the residual vectors are
$\vct R_1$, \dots $\vct R_M$
[where $\vct R_j \equiv \vct R(\vct f_j)$
for $j = 1, \dots, M$],
%
we wish to construct a more accurate solution
from the vectors.



To do so, we first find the combination of the residue vectors
$\vct{\hat R} = \sum_i c_i \, \vct R_i$,
that minimizes the magnitude
$\| \vct R \|$.
%
If Eq. \eqref{eq:R_f} is nearly linear,
%
$\vct{\hat R}$
is roughly the residue vector of
$\vct{\hat f} = \sum_i c_i \, \vct f_i$,
and
$\vct{\hat f}$
roughly achieves the minimal residue
among all linear combinations of
$\{ \vct f_i \}$.
%
Thus,
we expect an iteration based on
$\vct{\hat f}$
to be more efficient than that
based on any of
$\vct f_i$.


We now construct a new trial vector $\vct f^{(n)}$ as
%
\begin{equation}
\vct f^{(n)}
=
\vct{\hat f}
+
\alpha \, \vct{\hat R}( \vct{\hat f} ),
\end{equation}
%
where the factor $\alpha$ is $1.0$ in this study
(although a smaller value is recommended
for other applications\cite{kovalenko1999, howard2011}).
%
The new vector $\vct f^{(n)}$
is used to update the basis as follows.





\tikzstyle{emptydot}=[inner sep=0pt,minimum size=0.0mm]
\tikzstyle{fRarrow1}=[->, very thick, draw={rgb:red,4;white,1;gray,1}]
\tikzstyle{fRarrow2}=[->, very thick, draw={rgb:blue,4;white,1;gray,1}]
\tikzstyle{fRarrowx}=[->, very thick]
\tikzstyle{fRarr}=[->, thin]
\tikzstyle{fRlabel}=[inner sep=0pt, text=black!80!white]

\begin{figure}
  \begin{tikzpicture}
    %
    %
    % The potential function to minimize is
    %
    % F = 3/8 (x - 3/5)^2 + 5/8 (y - 4/5)^2 + 1/4 (x - 3/5) (y - 4/5)
    %   = 7/2 R^2
    %
    % x = 3/5
    %   + (sqrt(2) - 1) sqrt(3 + sqrt(2)) cos t
    %   + (sqrt(2) + 1) sqrt(3 - sqrt(2)) sin t.
    %
    % y = 4/5
    %   + sqrt(3 + sqrt(2)) cos t
    %   - sqrt(3 - sqrt(2)) sin t.
    %
    % The long axis is achieved at t = Pi/2
    % its length is sqrt(8 + 2 sqrt(2)) R,
    % and it is along the direction of
    %   (sqrt(2) + 1, -1),
    % which has an angle of -22.5 degrees
    % with the x axis.
    %
    % The short axis is achieved at t = 0,
    % its length is sqrt(8 - 2 sqrt(2)) R,
    % and it is along the direction of
    %   (sqrt(2) - 1, 1),
    % which has an angle of 67.5 degrees
    % with the x axis.
    %
    %
    \newcommand{\sz}{5cm}
    \begin{scope}
      %\clip ({-0.08*\sz}, {-0.08*\sz}) rectangle ({1.3*\sz}, {1.15*\sz});
      %
      % Draw ellipses
      %
      \foreach \i in {0,...,3}
      {
        \pgfmathsetmacro{\Fval}{0.13 - \i * 0.04};
        \pgfmathsetmacro{\Rval}{sqrt(\Fval*2/7)};
        \pgfmathsetmacro{\aval}{sqrt(8 + sqrt(8))*\Rval};
        \pgfmathsetmacro{\bval}{sqrt(8 - sqrt(8))*\Rval};
        \pgfmathsetmacro{\colora}{12 + 3 * \i};
        \draw[fill,
              gray!\colora!white,
              rotate around={67.5:(0.6*\sz, 0.8*\sz)}]
          (0.6*\sz, 0.8*\sz)
          ellipse ({\bval*\sz} and {\aval*\sz});
      }
      %
      %
      %
      \foreach \i in {1,...,19}
      {
        \pgfmathsetmacro\lambda{\i * 0.05};
        \pgfmathsetmacro\x{1 - \lambda};
        \pgfmathsetmacro\y{\lambda};
        \pgfmathsetmacro\dx{-0.1 + 0.5 * \lambda};
        \pgfmathsetmacro\dy{0.9 - 1.0 * \lambda};
        \pgfmathsetmacro\xx{\x + \dx};
        \pgfmathsetmacro\yy{\y + \dy};
        \draw [fRarr, draw={rgb:red,\x;blue,\y;white,1.5;gray,0.5}]
          (0, 0) -- (\x*\sz, \y*\sz) -- (\xx*\sz, \yy*\sz);
      }
      %
      %
      %
      % the minimum
      %
      %
      \draw
          (0.6*\sz, 0.8*\sz)
          node
            [ fill, circle, inner sep=0pt, minimum size=1.5mm,
              label={
                [inner sep=0.01*\sz]
                -45:{$\vct f^*$}
              }
            ] {};
      %
      % vector 1
      %
      \node (f1R1) at (0.9*\sz, 0.9*\sz)
        [ emptydot,
          label={[fRlabel,
                  label distance={0.05*\sz},
                  rotate=-83.7]
               20:{$\vct R_1$}}
        ] {};
      \node (f1) at (1.0*\sz, 0)
        [emptydot, label=below:{$\vct f_1$}]{}
        edge[fRarrow1] (f1R1);
      %
      % vector 2
      %
      \node (f2R2) at (0.4*\sz, 0.9*\sz)
        [ emptydot,
          label={[fRlabel,
                  label distance={0.03*\sz},
                  rotate=-14.0]
               93:{$\vct R_2$}}
        ] {};
      \node (f2) at (0, 1.0*\sz)
        [emptydot, label=left:{$\vct f_2$}]{}
        edge[fRarrow2] (f2R2);
      %
      %
      %
      \draw [black, dotted, thin]
        (-0.1*\sz, 1.1*\sz) -- (1.1*\sz, -0.1*\sz);
      %
      %
      %
      % optimal vector
      %
      %
      \node (fhatRhat) at (0.52*\sz, 0.9*\sz)
        [ emptydot,
          label={[fRlabel,
                  label distance={0.02*\sz},
                  rotate=26.6]
                -150:{$\vct {\hat R}$}}
        ] {};
      \node (fhat) at (0.24*\sz, 0.76*\sz)
        [ emptydot, inner sep=0,
          label={
            [label distance={0.03*\sz}]
            180:{$\vct {\hat f}$}
          }
        ] {}
        edge[fRarrowx] (fhatRhat);
      %
      %
      %
      \node (origin) at (0, 0) [emptydot]{}
        edge[fRarrow1] (f1)
        edge[fRarrow2] (f2)
        edge[fRarrowx] (fhat);
    \end{scope}
    %
    %
    %
    %
    % origin of the residual vectors
    %
    %
    %
    \newcommand{\Rox}{1.5*\sz}
    \newcommand{\Roy}{0.13*\sz}
    %
    %
    %
    \foreach \i in {1,...,19}
    {
      \pgfmathsetmacro\lambda{\i * 0.05}
      \pgfmathsetmacro\x{1 - \lambda};
      \pgfmathsetmacro\y{\lambda};
      \pgfmathsetmacro\dx{-0.1 + 0.5 * \lambda}
      \pgfmathsetmacro\dy{0.9 - 1.0 * \lambda}
      \draw [fRarr, draw={rgb:red,\x;blue,\y;white,1.5;gray,0.5}]
        (\Rox, \Roy) -- (\Rox + \dx*\sz, \Roy + \dy*\sz);
    }
    %
    %
    %
    \node (R1) at ({\Rox - 0.1 * \sz}, {\Roy + 0.9 * \sz})
      [ emptydot,
        label={[fRlabel, label distance=1.5mm]
               0:{$\vct R_1$}}
      ] {};
    %
    %
    %
    \node (R2) at ({\Rox + 0.4 * \sz}, {\Roy - 0.1 * \sz})
      [ emptydot,
        label={[fRlabel, label distance=1.5mm]
               0:{$\vct R_2$}}
      ] {};
    %
    %
    %
    \draw [blue!50!black, dotted, thin]
         ({\Rox - 0.15 * \sz}, {\Roy + 1.0 * \sz})
      -- ({\Rox + 0.45 * \sz}, {\Roy - 0.2 * \sz});
    %
    %
    %
    % Draw the perpendicular sign
    %
    %
    %
    \draw [thick, blue!50!gray]
          ({\Rox + 0.24*\sz}, {\Roy + 0.12*\sz})
       -- ({\Rox + 0.22*\sz}, {\Roy + 0.16*\sz})
       -- ({\Rox + 0.26*\sz}, {\Roy + 0.18*\sz});
    %
    %
    %
    \node (Rhat) at ({\Rox+0.28*\sz}, {\Roy+0.14*\sz})
      [ emptydot,
        label={[fRlabel, label distance=0.1mm]
               10:{$\vct {\hat R}$}}
      ] {};
    %
    %
    %
    \node (Rorigin) at (\Rox, \Roy) [emptydot] {}
      edge[fRarrow1] (R1)
      edge[fRarrow2] (R2)
      edge[fRarrowx] (Rhat);
    %
    %
    %
  \end{tikzpicture}
  %
  %
  %
  \caption{\label{fig:scheme}
    Schematic illustration of the method of
    direct inversion of the iterative subspace (DIIS)
    for solving a set of equation.
    %
    Each trial vector $\vct f_i$
    represents an approximate solution,
    and the residual vector $\vct R_i$
    represents the error.
    %
    Given a basis of a few (two here) trial vectors,
    DIIS seeks the combination
    $\vct {\hat R} = \sum_i c_i \, \vct R_i$
    that minimizes the magnitude
    $\| \vct{\hat R} \|$
    under the constraint
    $\sum_i c_i = 1$ (left).
    %
    The coefficients, $c_i$, are used
    to combine the trial vectors as
    $\vct {\hat f} = \sum_i c_i \, \vct f_i$.
    %
    The new trial vector is given by
    $\vct f^{(n)} = \vct {\hat f} + \vct {\hat R}$.
    %
    For the next round of iteration,
    $\vct f^{(n)}$ is normally either added
    to the basis, or used to replace an existing vector
    in the basis.
  }
\end{figure}




\subsection{Basis updating}



In each iteration of DIIS,
the basis is updated
by the new trial vector $\vct f^{(n)}$
from the above iteration step.
%
Initially,
the basis contains a single vector.
%
As we add more vectors into the basis,
some old vectors are removed
to maintain a maximal size of $M$.



In a popular updating scheme\cite{kovalenko1999},
the basis is treated as a queue:
%
we add $\vct f^{(n)}$ to the basis,
if the basis contains fewer than $M$ vectors,
%
or substitute $\vct f^{(n)}$ for the earliest vector in the basis.
%
If, however, $\vct f^{(n)}$
produces an error greater than
$K_r$ times the error of
$\vct f_\mathrm{min}$,
the least erroneous vector in the basis,
%
we rebuild the basis
from $\vct f_\mathrm{min}$.
%
Here, the error of a vector $\vct f$ is defined as
the magnitude of the residual vector as
$\| \vct R(\vct f) \|$,
and
$K_r = 10.0$\cite{
kovalenko1999}.



We used the following alternative
in this study.
%An alternative is the following.
%
First, we find the most erroneous vector,
$\vct f_\mathrm{max}$, from the basis.
%
If the new vector, $\vct f^{(n)}$,
produces an error less than $\vct f_\mathrm{max}$,
we add $\vct f^{(n)}$ into the basis
or, if the basis is full,
substitute $\vct f^{(n)}$ for $\vct f_\mathrm{max}$.
%
Otherwise,
we remove $\vct f_\mathrm{max}$ from the basis,
and if this empties the basis,
we rebuild the basis from $\vct f^{(n)}$.
%
% We find the modification is slightly better.



In both cases,
DIIS recovers the direct implementation
if $M = 1$.
%
Thus,
the method is effective
only if multiple bases are used.





\section{Results}





The direct and DIIS versions of WHAM
were tested on three systems.
%
In both cases,
the initial free energy was obtained from
the single histogram method:
%
\begin{equation*}
f_i - f_{i-1}
=
\log
\left\langle
  \exp\left[
    (\beta_j - \beta_{j-1}) \, E
  \right]
\right\rangle_j
\end{equation*}
%
Iterations were not stopped
until each $|R_i| < 10^{-10}$.



The first system is
the two-dimensional $64\times64$ Ising model.
%
We used parallel tempering\cite{
  swendsen1986, *geyer1991, *hukushima1996, *hansmann1997,
  *earl2005}
Monte Carlo (MC)
with
eighty temperatures: $T = 1.5$, $1.52$, \dots, $3.08$.



The second system is the 108-particle Lennard-Jones system.
%
Molecular dynamics (MD)
was used with a time step of $0.002$.
The velocity rescaling thermostat\cite{bussi2007}
was used with a time step of $0.02$.
%
The potential was cutoff at $r = 2.5$.
%
We simulated the system under
the canonical ($NVT$), and isothermal-isobaric ($NPT$) ensembles,
both using parallel tempering.
%
For the $NVT$ ensemble,
we used ten temperatures: $T = 0.7, 0.8, \dots, 1.6$,
and fixed the density at $\rho = 0.3$.
%
For the $NpT$ ensemble,
we simulated the system
under $N_T \times N_p = 5\times 10$ conditions:
the temperatures were $T = 1.0, 1.1, \dots, 1.4$,
the pressures were $p = 0.2, 0.4, \dots, 1.8$.
%
The position Langevin barostat based on $\log V$
was used with a step size of $10^{-5}$.



The third system is a mini-protein:
villin headpiece\cite{duan1998}
(PDB ID: 1VII).
%
The protein was immersed in
a dodecahedron box with 1898 water molecules and two chloride ions.
%
MD simulations were performed
using GROMACS\cite{
  berendsen1995, *lindahl2001, *vanderspoel2005, *hess2008}.
%
The electronic interaction was
handled by the particle mesh Ewald method\cite{
  essmann1995}.
%
The constraints were handled by the LINCS method\cite{
  hess1997}
for hydrogen-related chemical bonds on the protein
and by the SETTLE method\cite{
  miyamoto1992}
for water molecules.
%
Both $NVT$ and $NPT$ ensembles were used.
%
In both cases, we simulated the system
for about {\color{red} 100} ns
under 12 conditions
(the time step was 2 fs).
%
Energy frames were registered every 0.1 ps.
%
In the $NVT$ case,
$T$ = 300 K, 310 K, \dots, 410 K.
%
In the $NpT$ case,
the temperatures were the same,
and the pressures were
1.0 bar, 1.1 bar, \dots, 2.1 bar,
respectively.



The results are shown in Fig. \ref{fig:niter}.
%
The tested cases
all required hundreds or thousands iterations
for the direct method of WHAM.
%
The performance of the DIIS version of WHAM
generally improved with increasing number of bases,
although in some cases an optimal $M$ existed.
%
Optimally, DIIS can deliver a speedup of one or two orders of magnitude.
%
However, the result is highly system dependent.
%
Generally, we expect a larger gain from DIIS
for a more complex system.




\begin{figure}[h]
  \makebox[\linewidth][c]{
    \includegraphics[angle=0, width=0.9\linewidth]{fig/niter.pdf}
  }
  \caption{
    \label{fig:niter}
    Number of iterations versus the number of bases, $M$
    in the DIIS version of WHAM.
    %
    The $M = 1$ result corresponds to the direct iteration.
    %
    For the Ising model and Lennard-Jones fluid,
    the results have been averaged over many independent samples.
    %
    For the villin headpiece,
    roughly 10\% of the trajectory frames
    were randomly selected to build a sample each time.
    %
    The lines are to guide the eyes.
  }
\end{figure}





\section{Acknowledgments}



It is a pleasure to thank Dr. Y. Zhao
for many helpful discussions.
%
Computer time on the Lonestar supercomputer
at the Texas Advanced Computing Center
at the University of Texas at Austin
is gratefully acknowledged.



\bibliography{simul}
\end{document}
